{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and validation samples for BERT\n",
    "\n",
    "I'm borrowing some code from my train-test-validation project in order to produce train/test divide for BERT.\n",
    "\n",
    "Getting the train/test vs. validation split right can be challenging, because we want to avoid repeating *authors* from the train/test set in validation. (Or in both train and test for that matter.) Authorial diction is constant enough that this could become an unfair advantage for genres with a few prolific authors. We also want to ensure that the positive & negative classes within a given set have a similar distribution across historical time. (Otherwise the model will become a model of language change.) Building sets where all these conditions hold is more involved than a random sample of volumes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, glob\n",
    "import os, csv, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing the validation split.\n",
    "\n",
    "The functions defined below are used to create a train/test/validation divide, while also ensuring\n",
    "\n",
    "1. No author is present in more than one of those sets, so we don't overfit on a specific style.\n",
    "2. Positive and negative classes are equally distributed across time (so we don't end up modeling language change instead of genre!)\n",
    "\n",
    "But the best way to understand the overall workflow may be to scan down a few cells to the bottom function, **train_and_validate().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenlymatchdate(meta, tt_positives, v_positives, negatives):\n",
    "    '''\n",
    "    Given a metadata file, two lists of positive indexes and a (larger) list\n",
    "    of negative indexes, this assigns negatives that match the date distribution\n",
    "    of the two positive lists as closely as possible, working randomly so that\n",
    "    neither list gets \"a first shot\" at maximally close matches.\n",
    "    \n",
    "    The task is complicated by our goal of ensuring that authors are only\n",
    "    represented in the train/test OR the validation set. To do this while\n",
    "    using as much of our sample as we can, we encourage the algorithm to choose\n",
    "    works from already-selected authors when they fit the date parameters needed.\n",
    "    This is the function of the selected_neg_unmatched set: works by authors we have\n",
    "    chosen, not yet matched to a positive work.\n",
    "    '''\n",
    "    \n",
    "    assert len(negatives) > (len(tt_positives) + len(v_positives))\n",
    "    authors = dict()\n",
    "    authors['tt'] = set(meta.loc[tt_positives, 'author'])\n",
    "    authors['v'] = set(meta.loc[v_positives, 'author'])\n",
    "    \n",
    "    neg_matched = dict()\n",
    "    neg_matched['tt'] = []\n",
    "    neg_matched['v'] = []\n",
    "    neg_unmatched = dict()\n",
    "    neg_unmatched['v'] = []\n",
    "    neg_unmatched['tt'] = []\n",
    "    \n",
    "    negative_meta = meta.loc[negatives, : ]\n",
    "    \n",
    "    allpositives = [(x, 'tt') for x in tt_positives]\n",
    "    allpositives.extend([(x, 'v') for x in v_positives])\n",
    "    random.shuffle(allpositives)\n",
    "    \n",
    "    for idx, settype in allpositives:\n",
    "        if settype == 'v':\n",
    "            inversetype = 'tt'\n",
    "        else:\n",
    "            inversetype = 'v'\n",
    "            \n",
    "        date = meta.loc[idx, 'firstpub']\n",
    "        found = False\n",
    "        negative_meta = negative_meta.assign(diff = np.abs(negative_meta['firstpub'] - date))\n",
    "        \n",
    "        for idx2 in neg_unmatched[settype]:\n",
    "            matchdate = meta.loc[idx2, 'firstpub']\n",
    "            if abs(matchdate - date) < 3:\n",
    "                neg_matched[settype].append(idx2)\n",
    "                location = neg_unmatched[settype].index(idx2)\n",
    "                neg_unmatched[settype].pop(location)\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            candidates = []\n",
    "            for i in range(200):\n",
    "                aspirants = negative_meta.index[negative_meta['diff'] == i].tolist()\n",
    "                \n",
    "                # the following section insures that authors in\n",
    "                # traintest don't end up also in validation\n",
    "                for a in aspirants:\n",
    "                    asp_author = meta.loc[a, 'author']\n",
    "                    if asp_author not in authors[inversetype]:\n",
    "                        # don't even consider books by authors already\n",
    "                        # in the other set\n",
    "                        candidates.append(a)\n",
    "                        \n",
    "                if len(candidates) > 0:\n",
    "                    break\n",
    "        \n",
    "            chosen = random.sample(candidates, 1)[0]\n",
    "            chosenauth = negative_meta.loc[chosen, 'author']\n",
    "            allbyauth = negative_meta.index[negative_meta['author'] == chosenauth].tolist()\n",
    "            authors[settype].add(chosenauth)\n",
    "            \n",
    "            if len(allbyauth) < 1:\n",
    "                print('error')\n",
    "                \n",
    "            for idx3 in allbyauth:\n",
    "                if idx3 == chosen:\n",
    "                    neg_matched[settype].append(idx3)\n",
    "                    # the one we actually chose\n",
    "                else:\n",
    "                    neg_unmatched[settype].append(idx3)\n",
    "                    # others by same author, to be considered first in future\n",
    "            \n",
    "            negative_meta.drop(allbyauth, inplace = True)\n",
    "            \n",
    "            if len(negative_meta) == 0:\n",
    "                print('Exhausted negatives! This is surprising.')\n",
    "                break\n",
    "    \n",
    "    # other books by same authors can be added to the set in the end\n",
    "    tt_neg = neg_matched['tt'] + neg_unmatched['tt']\n",
    "    v_neg = neg_matched['v'] + neg_unmatched['v']\n",
    "    \n",
    "    remaining_neg = negative_meta.index.tolist()\n",
    "\n",
    "    return tt_neg, v_neg, remaining_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags2tagset(x):\n",
    "    ''' function that will be applied to transform\n",
    "    fantasy | science-fiction into {'fantasy', 'science-fiction'} '''\n",
    "    if type(x) == float:\n",
    "        return set()\n",
    "    else:\n",
    "        return set(x.split(' | '))\n",
    "\n",
    "def divide_training_from_validation(tags4positive, tags4negative, sizecap, metadatapath):\n",
    "    ''' This function divides a dataset into two parts: a training-and-test set, and a\n",
    "    validation set. We ensure that authors are represented in one set *or* the other,\n",
    "    not both.\n",
    "    \n",
    "    A model is optimized by gridsearch and crossvalidation on the training-and-test set. Then this model\n",
    "    is applied to the validation set, and accuracy is recorded.\n",
    "    '''\n",
    "    \n",
    "    meta = pd.read_csv(metadatapath)\n",
    "    column_of_sets = meta['genretags'].apply(tags2tagset)\n",
    "    meta = meta.assign(tagset = column_of_sets)\n",
    "    \n",
    "    overlap = []\n",
    "    negatives = []\n",
    "    positives = []\n",
    "    \n",
    "    for idx, row in meta.iterrows():\n",
    "        if 'drop' in row['tagset']:\n",
    "            continue\n",
    "            # these works were dropped and will not be present in the data folder\n",
    "            \n",
    "        posintersect = len(row['tagset'] & tags4positive)\n",
    "        negintersect = len(row['tagset'] & tags4negative)\n",
    "        \n",
    "        if posintersect and negintersect:\n",
    "            overlap.append(idx)\n",
    "        elif posintersect:\n",
    "            positives.append(idx)\n",
    "        elif negintersect:\n",
    "            negatives.append(idx)\n",
    "            \n",
    "    print()\n",
    "    print('-------------')\n",
    "    print('Begin construction of validation split.')\n",
    "    print(\"Positives/negatives:\", len(positives), len(negatives))\n",
    "    \n",
    "    random.shuffle(overlap)\n",
    "    print('Overlap (assigned to pos class): ' + str(len(overlap)))\n",
    "    positives.extend(overlap)\n",
    "    \n",
    "    # We do selection by author\n",
    "    positiveauthors = list(set(meta.loc[positives, 'author'].tolist()))\n",
    "    \n",
    "    random.shuffle(positiveauthors)\n",
    "    \n",
    "    traintest_pos = []\n",
    "    validation_pos = []\n",
    "    donewithtraintest = False\n",
    "    \n",
    "    for auth in positiveauthors:\n",
    "        this_auth_indices = meta.index[meta['author'] == auth].tolist()\n",
    "        confirmed_auth_indices = []\n",
    "        for idx in this_auth_indices:\n",
    "            if idx in positives:\n",
    "                confirmed_auth_indices.append(idx)\n",
    "        \n",
    "        if not donewithtraintest:\n",
    "            traintest_pos.extend(confirmed_auth_indices)\n",
    "        else:\n",
    "            validation_pos.extend(confirmed_auth_indices)\n",
    "        \n",
    "        if len(traintest_pos) > sizecap:\n",
    "            # that's deliberately > rather than >= because we want a cushion\n",
    "            donewithtraintest = True\n",
    "    \n",
    "    # Now let's get a set of negatives that match the positives' distribution\n",
    "    # across the time axis.\n",
    "    \n",
    "    traintest_neg, validation_neg, remaining_neg = evenlymatchdate(meta, traintest_pos, validation_pos, negatives)\n",
    "    \n",
    "    # For Bert, we want an equal number of positive and negative vols,\n",
    "    # because there will be no subsequent winnowing. This departs from\n",
    "    # our practice with versatiletrainer2.\n",
    "    \n",
    "    if len(traintest_neg) > len(traintest_pos):\n",
    "        k = len(traintest_pos)\n",
    "        traintest_neg = random.sample(traintest_neg, k)\n",
    "        \n",
    "    traintest = meta.loc[traintest_pos + traintest_neg, : ]\n",
    "    realclass = ([1] * len(traintest_pos)) + ([0] * len(traintest_neg))\n",
    "    traintest = traintest.assign(realclass = realclass)\n",
    "    print(\"Traintest pos/neg:\", len(traintest_pos), len(traintest_neg))\n",
    "    \n",
    "    if len(validation_neg) > len(validation_pos):\n",
    "        validation_neg = validation_neg[0: len(validation_pos)]\n",
    "        # we want the balance of pos and neg examples to be even\n",
    "        \n",
    "    print(\"Validation pos/neg:\", len(validation_pos), len(validation_neg))\n",
    "    \n",
    "    validation = meta.loc[validation_pos + validation_neg, : ]\n",
    "    realclass = ([1] * len(validation_pos)) + ([0] * len(validation_neg))\n",
    "    validation = validation.assign(realclass = realclass)\n",
    "    \n",
    "    return traintest, validation \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting snippets.\n",
    "\n",
    "Once we have lists of volumes for the train and validation sets, we iterate through each list and get BERT-sized snippets from each volume in the list. A parameter *n* defines the maximum number we can take.\n",
    "\n",
    "The lines are shuffled and written to file in BERT-appropriate format.\n",
    "\n",
    "We also save a row-level metadata file for the validation (\"dev\") set; this can be used later to group snippets by volume and interpret accuracy at the volume level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_separation(df1, df2):\n",
    "    '''\n",
    "    Just some stats on the train/test vs validation split.\n",
    "    '''\n",
    "    \n",
    "    authors1 = set(df1['author'])\n",
    "    authors2 = set(df2['author'])\n",
    "    overlap = authors1.intersection(authors2)\n",
    "    if len(overlap) > 0:\n",
    "        print('Overlap: ', overlap)\n",
    "    \n",
    "    pos1date = np.mean(df1.loc[df1.realclass == 0, 'firstpub'])\n",
    "    neg1date = np.mean(df1.loc[df1.realclass == 1, 'firstpub'])\n",
    "    pos2date = np.mean(df2.loc[df2.realclass == 0, 'firstpub'])\n",
    "    neg2date = np.mean(df2.loc[df2.realclass == 1, 'firstpub'])\n",
    "    \n",
    "    print(\"Traintest mean date pos:\", pos1date, \"neg:\", neg1date)\n",
    "    print(\"Validation mean date pos\", pos2date, \"neg:\", neg2date)\n",
    "    print()\n",
    "\n",
    "def get_snippets(anid, n, snipmaxlen):\n",
    "    '''\n",
    "    Returns snippets from a file. The number of snippets\n",
    "    is determined by the parameter n, the length of\n",
    "    snippets by snipmaxlen.\n",
    "    '''\n",
    "    \n",
    "    inpath = '../newtexts/' + anid + '.txt'\n",
    "    with open(inpath, encoding = 'utf-8') as f:\n",
    "        filelines = f.readlines()\n",
    "        words = []\n",
    "        for line in filelines:\n",
    "            newwords = line.strip().split()\n",
    "            words.extend(newwords)\n",
    "            \n",
    "    startsnip = False\n",
    "    snippets = []\n",
    "    snip = []\n",
    "            \n",
    "    # Note that we skip the first\n",
    "    for i in range(256, len(words)):\n",
    "        w = words[i]\n",
    "        if w.startswith('<p') and w.endswith('>'):\n",
    "            continue\n",
    "            # these are pagebreak marks\n",
    "            # I've inserted\n",
    "            \n",
    "        if not startsnip and (w.endswith('.') or w.endswith('?') or w.endswith('\"') or w.endswith(',')):\n",
    "            startsnip = True\n",
    "        elif startsnip and len(snip) < snipmaxlen:\n",
    "            snip.append(w.lower())\n",
    "            # we assume an uncased model\n",
    "            \n",
    "        elif len(snip) >= snipmaxlen:\n",
    "            snippets.append(' '.join(snip))\n",
    "            snip = []\n",
    "            startsnip = False\n",
    "    \n",
    "    # Note that we deliberately don't take the last (incomplete)\n",
    "    # snippet. It's likely to be uncharacteristic. We also skip the\n",
    "    # next to the last snippet for the same reason.\n",
    "    \n",
    "    max_n = len(snippets) - 1\n",
    "    \n",
    "    if max_n > n: \n",
    "        snippets = random.sample(snippets[0 : -1], n)\n",
    "        \n",
    "        # we do this random sampling in hopes of getting snippets across\n",
    "        # the whole length of the book (minus uncharacteristic start and end)\n",
    "    \n",
    "    return snippets, max_n\n",
    "\n",
    "def bertformat(df, n, snipmaxlen):\n",
    "    poslines = []\n",
    "    neglines = []\n",
    "    index = 0\n",
    "    snip_maxes = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        the_id = row.docid\n",
    "        the_class = row.realclass\n",
    "        \n",
    "        snippets, max_n = get_snippets(the_id, n, snipmaxlen)\n",
    "        snip_maxes.append(max_n)\n",
    "        \n",
    "        for s in snippets:\n",
    "            line = dict()\n",
    "            line['docid'] = the_id\n",
    "            line['idx'] = str(index)\n",
    "            line['class'] = str(the_class)\n",
    "            line['dummy'] = 'd'\n",
    "            line['text'] = s\n",
    "            # lineindex-tab-classlabel-tab-dummycolumn-tab-text\n",
    "            \n",
    "            if line['class'] == '1': \n",
    "                poslines.append(line)\n",
    "            else:\n",
    "                neglines.append(line)\n",
    "                \n",
    "            index += 1\n",
    "    \n",
    "    # we want equal pos and neg representation\n",
    "    minlen = min(len(poslines), len(neglines))\n",
    "    \n",
    "    poslines = poslines[0 : minlen]\n",
    "    neglines = neglines[0 : minlen]\n",
    "    \n",
    "    lines = poslines + neglines\n",
    "    \n",
    "    random.shuffle(lines)\n",
    "    outframe = pd.DataFrame(lines)\n",
    "    # the random shuffle is extremely important, given the way BERT works!\n",
    "    \n",
    "    print('Average possible snippets:', sum(snip_maxes) / len(snip_maxes))\n",
    "    print('Actual taken per vol: ', str((minlen * 2) / len(df)))\n",
    "    \n",
    "    return outframe\n",
    "    \n",
    "def create_traindev(modelname, tags4positive, tags4negative, sizecap, metadatapath, n, snipmaxlen):\n",
    "    \n",
    "    for i in range(1):\n",
    "        fullname = modelname\n",
    "        \n",
    "        traintest, validation = divide_training_from_validation(tags4positive, tags4negative, sizecap, metadatapath)\n",
    "        \n",
    "        confirm_separation(traintest, validation)\n",
    "    \n",
    "        traintest.to_csv('bertmeta/train_vols_' + fullname + '.csv', index = False)\n",
    "        validation.to_csv('bertmeta/dev_vols_' + fullname + '.csv', index = False)\n",
    "        \n",
    "        print()\n",
    "        print('Metadata written. Writing training data ...')\n",
    "        \n",
    "        train_df = bertformat(traintest, n, snipmaxlen)\n",
    "        train4bert = train_df.loc[ : , ['idx', 'class', 'dummy', 'text']]\n",
    "        train4bert.to_csv('bertdata/train_' + fullname + '.tsv', sep = '\\t', header = False, index = False, quoting = csv.QUOTE_NONE)\n",
    "                \n",
    "        print('... and validation data.')\n",
    "        print()\n",
    "        dev_df = bertformat(validation, n, snipmaxlen)\n",
    "        dev4bert = dev_df.loc[ : , ['idx', 'class', 'dummy', 'text']]\n",
    "        dev4bert.to_csv('bertdata/dev_' + fullname + '.tsv', sep = '\\t', header = False, index = False, quoting = csv.QUOTE_NONE)\n",
    "        devmeta = dev_df.loc[ : , ['idx', 'docid', 'class']]\n",
    "        devmeta.to_csv('bertmeta/dev_rows_' + fullname + '.tsv', sep = '\\t', index = False)\n",
    "        # we can use this to interpret results later, grouping them by docid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Begin construction of validation split.\n",
      "Positives/negatives: 166 370\n",
      "Overlap (assigned to pos class): 0\n",
      "Traintest pos/neg: 128 128\n",
      "Validation pos/neg: 38 38\n",
      "Traintest mean date pos: 1872.75 neg: 1872.140625\n",
      "Validation mean date pos 1895.578947368421 neg: 1894.3684210526317\n",
      "\n",
      "\n",
      "Metadata written. Writing training data ...\n",
      "Average possible snippets: 161.03515625\n",
      "Actual taken per vol:  134.9296875\n",
      "... and validation data.\n",
      "\n",
      "Average possible snippets: 171.56578947368422\n",
      "Actual taken per vol:  144.39473684210526\n"
     ]
    }
   ],
   "source": [
    "create_traindev('Goth512max', {'lochorror', 'pbgothic', 'locghost', 'stangothic', 'chihorror'},\n",
    "        {'random', 'chirandom'}, 125, '../meta/finalmeta.csv', 300, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Begin construction of validation split.\n",
      "Positives/negatives: 175 347\n",
      "Overlap (assigned to pos class): 23\n",
      "Traintest pos/neg: 126 126\n",
      "Validation pos/neg: 72 72\n",
      "Traintest mean date pos: 1938.8015873015872 neg: 1940.9920634920634\n",
      "Validation mean date pos 1933.486111111111 neg: 1933.625\n",
      "\n",
      "\n",
      "Metadata written. Writing training data ...\n",
      "Average possible snippets: 158.38492063492063\n",
      "Actual taken per vol:  138.515873015873\n",
      "... and validation data.\n",
      "\n",
      "Average possible snippets: 152.54166666666666\n",
      "Actual taken per vol:  140.72222222222223\n"
     ]
    }
   ],
   "source": [
    "create_traindev('SF512max', {'anatscifi', 'locscifi', 'chiscifi', 'femscifi'},\n",
    "        {'random', 'chirandom'}, 125, '../meta/finalmeta.csv', 300, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Begin construction of validation split.\n",
      "Positives/negatives: 206 327\n",
      "Overlap (assigned to pos class): 43\n",
      "Traintest pos/neg: 126 126\n",
      "Validation pos/neg: 123 123\n",
      "Traintest mean date pos: 1930.0873015873017 neg: 1930.3809523809523\n",
      "Validation mean date pos 1930.9756097560976 neg: 1931.520325203252\n",
      "\n",
      "\n",
      "Metadata written. Writing training data ...\n",
      "Average possible snippets: 160.76190476190476\n",
      "Actual taken per vol:  144.86507936507937\n",
      "... and validation data.\n",
      "\n",
      "Average possible snippets: 144.9959349593496\n",
      "Actual taken per vol:  127.32520325203252\n"
     ]
    }
   ],
   "source": [
    "create_traindev('Mystery512max', {'locdetective', 'locdetmyst', 'chimyst', 'det100'},\n",
    "        {'random', 'chirandom'}, 125, '../meta/finalmeta.csv', 300, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deprecated\n",
    "\n",
    "I was checking to make sure that snippets are evenly distributed across the length of a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5045118110236221\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5035007610350076\n",
      "0.5\n",
      "0.5009651898734178\n",
      "0.504534693877551\n",
      "0.5\n",
      "0.4980990099009901\n",
      "0.5\n",
      "0.5028068518664254\n",
      "0.48463201663201666\n",
      "0.5\n",
      "0.5\n",
      "0.5104120603015075\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5006194968553459\n",
      "0.4972224299065421\n",
      "0.486419595314164\n",
      "0.4939302325581395\n",
      "0.4984158415841584\n",
      "0.5099687546496057\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5064872107186358\n",
      "0.5\n",
      "0.5004580152671756\n",
      "0.5046385224274407\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5034262101534829\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.503568345323741\n",
      "0.5\n",
      "0.49811644832605534\n",
      "0.5\n",
      "0.4956188811188812\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.48377516339869286\n",
      "0.4952910447761194\n",
      "0.5\n",
      "0.49448452012383903\n",
      "0.5\n",
      "0.49851863857374396\n",
      "0.497234608985025\n",
      "0.4896973590292648\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.4989453125\n",
      "0.5\n",
      "0.5053383458646616\n",
      "0.5\n",
      "0.5\n",
      "0.4922493150684931\n",
      "0.5009964912280701\n",
      "0.5\n",
      "0.4973909648633575\n",
      "0.4998831615120275\n",
      "0.5\n",
      "0.4922722852512156\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5081350844277673\n",
      "0.4982775263951735\n",
      "0.4934920127795527\n",
      "0.5\n",
      "0.5034285714285714\n",
      "0.49877389984825493\n",
      "0.5059312977099236\n",
      "0.5036221374045802\n",
      "0.5064183796856107\n",
      "0.5071705069124424\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.49573958333333334\n",
      "0.4961507352941177\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5098395604395605\n",
      "0.5\n",
      "0.5021161118404295\n",
      "0.4925776173285198\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5028456790123457\n",
      "0.5\n",
      "0.5055822102425876\n",
      "0.49890978886756243\n",
      "0.49858823529411767\n",
      "0.5\n",
      "0.5\n",
      "0.49356249999999996\n",
      "0.4970330250990753\n",
      "0.49625255338904367\n",
      "0.4991332007952286\n",
      "0.49971276595744685\n",
      "0.5048638655462185\n",
      "0.5\n",
      "0.5\n",
      "0.5109560585885486\n",
      "0.5\n",
      "0.5\n",
      "0.5128966376089664\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.48904489795918366\n",
      "0.5037951635846373\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5006254071661238\n",
      "0.5\n",
      "0.5039267299864315\n"
     ]
    }
   ],
   "source": [
    "def number_snippets(anid):\n",
    "    '''\n",
    "    Returns 128-word snippets from a file. The number of snippets\n",
    "    is determined by the parameter n.\n",
    "    '''\n",
    "    \n",
    "    inpath = '../newtexts/' + anid + '.txt'\n",
    "    with open(inpath, encoding = 'utf-8') as f:\n",
    "        filelines = f.readlines()\n",
    "        words = []\n",
    "        for line in filelines:\n",
    "            newwords = line.strip().split()\n",
    "            words.extend(newwords)\n",
    "            \n",
    "    startsnip = False\n",
    "    snippets = []\n",
    "    snip = []\n",
    "            \n",
    "    # Note that we skip the first\n",
    "    for i in range(256, len(words)):\n",
    "        w = words[i]\n",
    "        if w.startswith('<p') and w.endswith('>'):\n",
    "            continue\n",
    "            # these are pagebreak marks\n",
    "            # I've inserted\n",
    "            \n",
    "        if not startsnip and w.endswith('.') or w.endswith('?') or w.endswith('\"'):\n",
    "            startsnip = True\n",
    "        elif startsnip and len(snip) < 127:\n",
    "            snip.append(w.lower())\n",
    "            # we assume an uncased model\n",
    "            \n",
    "        elif len(snip) >= 127:\n",
    "            snippets.append(' '.join(snip))\n",
    "            snip = []\n",
    "            startsnip = False\n",
    "    \n",
    "    # Note that we deliberately don't take the last (incomplete)\n",
    "    # snippet. It's likely to be uncharacteristic. We also skip the\n",
    "    # next to the last snippet for the same reason.\n",
    "    \n",
    "    snipdict = dict()\n",
    "    for i, s in enumerate(snippets):\n",
    "        snipdict[s] = i\n",
    "    maxsnip = i\n",
    "    \n",
    "    return snipdict, maxsnip\n",
    "\n",
    "for d in docs:\n",
    "    sd, maxsnip = number_snippets(d)\n",
    "    indexes = []\n",
    "    for s in data[3]:\n",
    "        if s in sd:\n",
    "            indexes.append(sd[s])\n",
    "    avg =(sum(indexes) / len(indexes))\n",
    "    print(avg/maxsnip)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sentiment data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snips(text):\n",
    "    \n",
    "    words = text.replace('\\t', ' ').replace('<br />', ' ').split()\n",
    "    snips = []\n",
    "    \n",
    "    for floor in range(0, len(words), 128):\n",
    "        ceiling = floor + 128\n",
    "        if ceiling > len(words):\n",
    "            ceiling = len(words)\n",
    "            \n",
    "        s = words[floor : ceiling]\n",
    "        if len(s) > 64:\n",
    "            snips.append(' '.join(s))\n",
    "                \n",
    "    return snips\n",
    "\n",
    "def get_dataset(rootfolder):\n",
    "    \n",
    "    negpaths = glob.glob(rootfolder + '/neg/*.txt')\n",
    "    pospaths = glob.glob(rootfolder + '/pos/*.txt')\n",
    "    paths = [(0, x) for x in negpaths] + [(1, x) for x in pospaths]\n",
    "    \n",
    "    index = 0\n",
    "    lines = []\n",
    "    \n",
    "    for label, p in paths:\n",
    "        docid = p.split('/')[-1].replace('.txt', '')\n",
    "        \n",
    "        with open(p) as f:\n",
    "            text = f.read().strip()\n",
    "            snips = get_snips(text)\n",
    "            \n",
    "            for s in snips:\n",
    "                line = dict()\n",
    "                line['docid'] = docid\n",
    "                line['idx'] = index\n",
    "                line['class'] = str(label)\n",
    "                line['dummy'] = 'd'\n",
    "                line['text'] = s\n",
    "                index += 1\n",
    "                lines.append(line)\n",
    "    \n",
    "    random.shuffle(lines)\n",
    "    outframe = pd.DataFrame(lines)\n",
    "    \n",
    "    return outframe\n",
    "            \n",
    "fullname = 'sentiment'\n",
    "\n",
    "train_df = get_dataset('/Volumes/TARDIS/aclImdb/train')\n",
    "\n",
    "train4bert = train_df.loc[ : , ['idx', 'class', 'dummy', 'text']]\n",
    "train4bert.to_csv('bertdata/train_' + fullname + '.tsv', sep = '\\t', header = False, index = False, quoting = csv.QUOTE_NONE)\n",
    "\n",
    "test_df = get_dataset('/Volumes/TARDIS/aclImdb/test')\n",
    "dev4bert = test_df.loc[ : , ['idx', 'class', 'dummy', 'text']]\n",
    "dev4bert.to_csv('bertdata/dev_' + fullname + '.tsv', sep = '\\t', header = False, index = False, quoting = csv.QUOTE_NONE)\n",
    "devmeta = test_df.loc[ : , ['idx', 'docid', 'class']]\n",
    "devmeta.to_csv('bertmeta/dev_rows_' + fullname + '.tsv', sep = '\\t', index = False)\n",
    "# we can use this to interpret results later, grouping them by docid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/TARDIS/aclImdb/train/neg/0_3.txt 0_3\n"
     ]
    }
   ],
   "source": [
    "rootfolder = '/Volumes/TARDIS/aclImdb/train'\n",
    "negpaths = glob.glob(rootfolder + '/neg/*.txt')\n",
    "n = negpaths[0]\n",
    "docid = n.split('/')[-1].replace('.txt', '')\n",
    "print(n, docid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(dev_df['class'], dtype = 'int8') > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long is the average movie review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.7872"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "def lengths_dataset(rootfolder):\n",
    "    \n",
    "    negpaths = glob.glob(rootfolder + '/neg/*.txt')\n",
    "    pospaths = glob.glob(rootfolder + '/pos/*.txt')\n",
    "    paths = [(0, x) for x in negpaths] + [(1, x) for x in pospaths]\n",
    "    \n",
    "    lens = []\n",
    "    \n",
    "    for label, p in paths:\n",
    "        \n",
    "        with open(p) as f:\n",
    "            words = f.read().split()\n",
    "            lens.append(len(words))\n",
    "            \n",
    "    \n",
    "    return sum(lens) / len(lens)\n",
    "\n",
    "lengths_dataset('/Volumes/TARDIS/aclImdb/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
